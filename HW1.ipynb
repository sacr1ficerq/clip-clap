{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNk09d6EqAx3"
   },
   "source": [
    "# ДЗ1. CLAP. Обучение проекции из аудио в текстовое пространство CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Описание задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQrsmgbkqXVZ"
   },
   "source": [
    "В этом задании вы построите упрощённый вариант модели CLAP (Contrastive Language-Audio Pretraining):\n",
    "\n",
    "- аудио прогоняется через предобученный аудио-энкодер (например, `LanguageBindAudio`, `CNN14/16` или другой);\n",
    "- текстовое описание пропускается через предобученный текстовый энкодер CLIP;\n",
    "- поверх аудио-векторов обучается линейный адаптер, который отображает аудио в то же пространство, что и текстовые эмбеддинги CLIP;\n",
    "- обучение идёт по *контрастивному лоссу*, все энкодеры заморожены, обучаются только параметры аудио-проекции (и, при желании, температура в лоссе);\n",
    "- качество полученного аудио-текстового пространства оценивается на задаче классификации / retrieval аудио по текстам на `AudioCaps`.\n",
    "\n",
    "Идея оценки: если всё сделано правильно, для аудио и его описания косинусное сходство эмбеддингов будет выше, чем для аудио и нерелевантных текстов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJupjjbsrTwJ"
   },
   "source": [
    "**Формулировка задач**\n",
    "\n",
    "0. Выбор аудио-энкодера.\n",
    "   Выберите и обоснуйте предобученный аудио-энбеддер:  \n",
    "   - `LanguageBindAudio`,  \n",
    "   - или CNN-модель (например, PANNs CNN14/16),  \n",
    "   - или другой открытый аудио-энкодер, который выдаёт фиксированный эмбеддинг.\n",
    "\n",
    "1. Подсчёт эмбеддингов.\n",
    "   - Посчитайте аудио-векторы для всех аудио из `AudioCaps` с помощью выбранного энкодера.  \n",
    "   - Посчитайте текстовые векторы для подписей с помощью `CLIP text encoder`.\n",
    "\n",
    "2. Линейная аудио-проекция.\n",
    "   - Реализуйте модель `AudioProjection`, переводящую аудио-эмбеддинг в размерность текстового эмбеддинга CLIP.\n",
    "\n",
    "3. Контрастивное обучение.\n",
    "   - Обучите аудио-проекцию на датасете `AudioCaps` по схеме аудио ↔ текст с контрастивным лоссом.  \n",
    "   - Аудио-энкодер и CLIP должны быть полностью заморожены.\n",
    "\n",
    "4. Оценка качества.\n",
    "   - Оцените качество полученного аудио-текстового пространства на задаче классификации/ретривала аудио:  \n",
    "     для каждого аудио найдите наиболее похожую текстовую подпись в батче/валидации и посчитайте `accuracy@1/3/10`.  \n",
    "   - Сравните результаты с *случайным бейзлайном*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03jAx63StYdA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Сеттинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw2WU446ta5Y"
   },
   "source": [
    "> Подготовьте все необходимые импорты и загрузите необходимые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SbHqYh_Qt4BL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in DATA_ROOT: ['audiocaps_val_new.tsv', 'audiocaps_val.tsv', 'test_texts.json', 'val_texts.json', 'audiocaps_test_new.tsv', 'audiocaps_train.tsv', 'audiocaps_test.tsv', 'audio']\n"
     ]
    }
   ],
   "source": [
    "# Для загрузки AudioCaps можно воспользоваться этим кодом\n",
    "import os\n",
    "\n",
    "# !gdown --id 1FAVKNWXp5afgoNmclDwnj8j_OFTBRmIb -O audiocaps.zip\n",
    "# !unzip audiocaps -d audiocaps\n",
    "\n",
    "DATA_ROOT = \"./audiocaps\"\n",
    "print(\"Files in DATA_ROOT:\", os.listdir(DATA_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCcgZWsbthgL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Задание 1. Подготовка аудио- и текстовых энкодеров (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RbbFApuuXml"
   },
   "source": [
    "В этом задании вам нужно:\n",
    "\n",
    "1. Выбрать аудио-энкодер и инициализировать его.\n",
    "2. Инициализировать текстовый энкодер CLIP. Вы свободны выбирать самостоятельно, какой имеено.\n",
    "3. Заморозить параметры обоих энкодеров (мы не дообучаем их, а учим только линейный адаптер).\n",
    "\n",
    "Вы можете:\n",
    "\n",
    "* использовать `LanguageBindAudio` (потребует установки репозитория и зависимостей);\n",
    "* или подставить свою аудио-модель (главное - чтобы на выходе был вектор фиксированной размерности).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7mM2dkqtYDI"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ┌(ಠ_ಠ)┘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6BdjCPcvrK7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Задание 2. Предподсчёт аудио- и текстовых эмбеддингов (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5kz9a_VvxCs"
   },
   "source": [
    "> Важный момент, который пригодится вам и в других домашних.\n",
    "\n",
    "Чтобы не тратить время на многократный прогон энкодеров при обучении, следует:\n",
    "\n",
    "1. Предварительно посчитывать аудио-эмбеддинги для каждого `.flac` в train/val/test.\n",
    "2. Записывать их в файл формата `pickle` (например), где ключ - имя файла, значение - numpy-вектор.\n",
    "3. Аналогично посчитать текстовые эмбеддинги для подписей через CLIP и совместить их с аудио.\n",
    "\n",
    "Рекомендуемая структура:\n",
    "\n",
    "* функция `extract_audio_vectors_with_checkpointing(...)` - обходит файлы, считает эмбеддинги, периодически делает чекпоинты;\n",
    "* функция `extract_text_embeddings(texts, clip_model, clip_processor)` - возвращает список текстовых эмбеддингов;\n",
    "* функция `process_dataset(...)` - читает `.tsv`, мержит аудио-эмбеддинги и текстовые, сохраняет список словарей вида  \n",
    "  `{\"uniq_id\": ..., \"audio_embedding\": ..., \"text_embedding\": ...}` в pickle.\n",
    "\n",
    "> Вы вольны отходить от предлагаемой структуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9OIM6ojkKQk"
   },
   "outputs": [],
   "source": [
    "# your code here (づ｡◕‿‿◕｡)づ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OD_skxfxBVY",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Задание 3. Линейный аудио-адаптер и контрастивный лосс (3 балла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCDte8VBw9ql"
   },
   "source": [
    "Теперь, когда у нас есть пары *audio_embedding, text_embedding*, реализуем:\n",
    "\n",
    "1. Класс `AudioTextDataset`, который читает pickle с комбинированными эмбеддингами.\n",
    "2. Линейную модель `AudioProjection`, переводящую аудио-эмбеддинг в размерность текстового.\n",
    "3. Контрастивный лосс для аудио↔текст:\n",
    "   - нормализовать эмбеддинги по L2;\n",
    "   - посчитать матрицу сходства;\n",
    "   - задать таргеты как `targets = arange(batch_size)`;\n",
    "   - вычислить `CrossEntropyLoss` как для строк audio→text и для строк text→audio, усреднить.\n",
    "\n",
    "Обучаем **только** `AudioProjection` (и, по желанию, параметр temperature).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypQ42sQ9zs7Q"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# (╯°□°）╯︵ ┻━┻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-kkEEuzx_Vi",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Задание 4. Оценка качества на задаче классификации аудио (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EQbXbIAyRM-"
   },
   "source": [
    "\n",
    "Теперь нужно понять, насколько хорошо аудио-векторы после проекции \"попадают\" в пространство текстовых эмбеддингов:\n",
    "\n",
    "1. Посчитайте проекции аудио для всех примеров в валидации.\n",
    "2. Для каждого аудио найдите `top-k` наиболее похожих текстов по косинусному сходству (или скалярному произведению после L2-нормализации).\n",
    "3. Посчитайте `accuracy@1`, `accuracy@3`, `accuracy@10`, т.е. долю случаев, когда \"правильный\" текст попал в топ-k.\n",
    "4. Сравните с неким *случайным бейзлайном*: для каждого аудио выберите `k` случайных текстов и посчитайте такую же метрику.\n",
    "\n",
    "> Важно: в батче класс \"правильного\" текста для i-го аудио - это индекс i (как в контрастивном лоссе)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RFrO9tRoylVl"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# (⌐■_■)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEoUVkEQxp05",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1e1D5QMy3yP"
   },
   "source": [
    "Оформите, пожалуйста, небольшой вывод. Например, можно воспрользоваться следующим планом:\n",
    "\n",
    "   * какую аудио-модель вы выбрали и почему;\n",
    "   * как вели себя потери на обучении;\n",
    "   * какие значения метрик получились и насколько они превосходят случайный baseline;\n",
    "   * любые наблюдения (например, зависимость от числа эпох, размера батча и т.д.);\n",
    "   * милые пожелания ассистенту/лектору, который будет это проверять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_e9rsiIzhHE"
   },
   "source": [
    "your text here (ಠ.ಠ)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP LSTM",
   "language": "python",
   "name": "hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
